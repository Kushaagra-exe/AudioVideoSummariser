{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a83f7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting decorator<5.0,>=4.0.2 (from moviepy)\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting imageio<3.0,>=2.5 (from moviepy)\n",
      "  Downloading imageio-2.36.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "  Downloading imageio_ffmpeg-0.5.1-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from moviepy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from moviepy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from moviepy) (2.32.3)\n",
      "Collecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (10.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (72.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n",
      "Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Downloading imageio-2.36.0-py3-none-any.whl (315 kB)\n",
      "Downloading imageio_ffmpeg-0.5.1-py3-none-win_amd64.whl (22.6 MB)\n",
      "   ---------------------------------------- 0.0/22.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.1/22.6 MB 10.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.5/22.6 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 7.1/22.6 MB 11.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 9.4/22.6 MB 11.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 11.8/22.6 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 14.2/22.6 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 16.5/22.6 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 18.9/22.6 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 21.5/22.6 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 22.6/22.6 MB 11.1 MB/s eta 0:00:00\n",
      "Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Building wheels for collected packages: moviepy\n",
      "  Building wheel for moviepy (setup.py): started\n",
      "  Building wheel for moviepy (setup.py): finished with status 'done'\n",
      "  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110755 sha256=5a1d9e126b537ebed2e5540f5311fa9e9ce063d99b6903d6c63d51dac203606e\n",
      "  Stored in directory: c:\\users\\kushaagra mehta\\appdata\\local\\pip\\cache\\wheels\\df\\ba\\4b\\0917fc0c8833c8ba7016565fc975b74c67bc8610806e930272\n",
      "Successfully built moviepy\n",
      "Installing collected packages: imageio_ffmpeg, imageio, decorator, proglog, moviepy\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "Successfully installed decorator-4.4.2 imageio-2.36.0 imageio_ffmpeg-0.5.1 moviepy-1.0.3 proglog-0.1.10\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe33c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from SpeechRecognition) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from SpeechRecognition) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2024.7.4)\n",
      "Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl (32.8 MB)\n",
      "   ---------------------------------------- 0.0/32.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.6/32.8 MB 8.4 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 3.1/32.8 MB 8.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 4.7/32.8 MB 7.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 6.3/32.8 MB 7.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 8.4/32.8 MB 8.0 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 10.5/32.8 MB 8.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 12.8/32.8 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 14.9/32.8 MB 8.9 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 17.6/32.8 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 20.2/32.8 MB 9.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 22.8/32.8 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 24.9/32.8 MB 9.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 27.5/32.8 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 30.1/32.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  32.2/32.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 32.8/32.8 MB 10.0 MB/s eta 0:00:00\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.10.4\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f27993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76b438b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "video = mp.VideoFileClip(\"vid 2.mp4\")\n",
    "audio_file = video.audio \n",
    "audio_file.write_audiofile(\"audio2.wav\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0b7d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0ceca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sr.AudioFile(\"audio2.wav\") as source: \n",
    "    data = r.record(source) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "707ccae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r.recognize_google(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ca882de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vidtext = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "131286c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The resultant text from video is: \n",
      "\n",
      "online to improve search results on images to better find objects and on music to enhance the ability to detect the motion boosting is another method of on sampling machine learning model in contrast with banks new models by training the models better than the data that the previous model mathematics performance especially if you are trying to increase performance on harder or less common examples of\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThe resultant text from video is: \\n\") \n",
    "print(vidtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1bc8a",
   "metadata": {},
   "source": [
    "# Way 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e43009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "627660ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kushaagra Mehta\\anaconda3\\envs\\Gen_env\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49ec631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_voice_file(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts the input audio file to WAV format if necessary and returns the path to the WAV file.\n",
    "    \"\"\"\n",
    "    if os.path.splitext(path)[1] == '.wav':\n",
    "        return path\n",
    "    elif os.path.splitext(path)[1] in ('.mp3', '.m4a', '.ogg', '.flac'):\n",
    "        audio_file = AudioSegment.from_file(\n",
    "            path, format=os.path.splitext(path)[1][1:])\n",
    "        wav_file = os.path.splitext(path)[0] + '.wav'\n",
    "        audio_file.export(wav_file, format='wav')\n",
    "        return wav_file\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f'Unsupported audio format: {format(os.path.splitext(path)[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baf0052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79bacb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_data, language) -> str:\n",
    "    \"\"\"\n",
    "    Transcribes audio data to text using Google's speech recognition API.\n",
    "    \"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    text = r.recognize_google(audio_data, language=language)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f940fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_transcription_to_file(text, output_file) -> None:\n",
    "    \"\"\"\n",
    "    Writes the transcribed text to the output file.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e934775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text(input_path: str, output_path: str, language: str) -> None:\n",
    "    \"\"\"\n",
    "    Transcribes an audio file at the given path to text and writes the transcribed text to the output file.\n",
    "    \"\"\"\n",
    "    wav_file = prepare_voice_file(input_path)\n",
    "    with sr.AudioFile(wav_file) as source:\n",
    "        audio_data = sr.Recognizer().record(source)\n",
    "        text = transcribe_audio(audio_data, language)\n",
    "        write_transcription_to_file(text, output_path)\n",
    "        print('Transcription:')\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b964a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the path to an audio file (WAV, MP3, M4A, OGG, or FLAC):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Please enter the path to an audio file (WAV, MP3, M4A, OGG, or FLAC):')\n",
    "input_path = input().strip()\n",
    "if not os.path.isfile(input_path):\n",
    "    print('Error: File not found.')\n",
    "else:\n",
    "    print('Please enter the path to the output file:')\n",
    "    output_path = input().strip()\n",
    "    print('Please enter the language code (e.g. en-US):')\n",
    "    language = input().strip()\n",
    "    try:\n",
    "        speech_to_text(input_path, output_path, language)\n",
    "    except Exception as e:\n",
    "        print('Error:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a9011",
   "metadata": {},
   "source": [
    "# Youtube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24278bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube_transcript_api\n",
      "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from youtube_transcript_api) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests->youtube_transcript_api) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests->youtube_transcript_api) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests->youtube_transcript_api) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests->youtube_transcript_api) (2024.7.4)\n",
      "Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: youtube_transcript_api\n",
      "Successfully installed youtube_transcript_api-0.6.2\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube_transcript_api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188a99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45dfba3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hZObUx6AfXM'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.youtube.com/watch?v=hZObUx6AfXM&pp=ygUVYm9vc3RpbmdpbiAyIG1pbnV0ZXMg\"\n",
    "id = url.split(\"&\")[0].split(\"=\")[1]\n",
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322f16f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transript = YouTubeTranscriptApi.get_transcript(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1709b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for i in transript:\n",
    "    text += \" \"+i['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f6bc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " variants of boosting have been used online to improve search results on images to better find objects and on music to enhance the ability to detect emotions boosting is another method of ensembling machine learning models similar to bagging in contrast with bagging though boosting iteratively creates new models by training the models to better learn the data that the previous model misclassified boosting starts with training a model on the original data set normally then for every example that was misclassified they increased the weights and for every example that they classified correctly they decreased the weights the weights here are ways of mathematically expressing the importance of a training sample to our model the higher the weight the more the model tries to learn to predict that example correctly so the new classifier is trained on the weighted data and then we see what examples it got right and what examples it got wrong re-weight the data and repeat it again until we have a number of models the prediction for this ensemble is a weighted sum of all the models we trained the weights here are based on the percentage of the data each model predicted correctly this allows us to combine all the models predictions and adjust the result based on how confident we are in each of our models overall boosting's super nice it's often used when trying to increase performance especially if you are trying to increase performance on harder or less common examples it can give better performance increases compared to bagging but it's also slower to train one potential thing you might have noticed is that boosting can learn bad examples that a normal model would have ignored it could learn to predict examples that are incorrectly labeled how would you change boosting to fix this issue\n"
     ]
    }
   ],
   "source": [
    "yttext = text\n",
    "print(yttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7754d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"You are Yotube video summarizer. You will be taking the transcript text and summarizing the entire video and providing the important summary in points within 250 words. Text:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e07de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94582029",
   "metadata": {},
   "source": [
    "# Summarisation using gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3bfd4121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google.generativeai\n",
      "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.10 (from google.generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google.generativeai)\n",
      "  Downloading google_api_core-2.21.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting google-api-python-client (from google.generativeai)\n",
      "  Downloading google_api_python_client-2.149.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google.generativeai)\n",
      "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting protobuf (from google.generativeai)\n",
      "  Downloading protobuf-5.28.2-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: pydantic in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from google.generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from google.generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from google.generativeai) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.10->google.generativeai)\n",
      "  Using cached proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google.generativeai)\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from google-api-core->google.generativeai) (2.32.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google.generativeai)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google.generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google.generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from pydantic->google.generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from pydantic->google.generativeai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from tqdm->google.generativeai) (0.4.6)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google.generativeai)\n",
      "  Downloading grpcio-1.67.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google.generativeai)\n",
      "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google.generativeai)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kushaagra mehta\\anaconda3\\envs\\gen_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google.generativeai) (2024.7.4)\n",
      "Downloading google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
      "   ---------------------------------------- 0.0/760.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 760.0/760.0 kB 10.6 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.21.0-py3-none-any.whl (156 kB)\n",
      "Downloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "Downloading protobuf-5.28.2-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading google_api_python_client-2.149.0-py2.py3-none-any.whl (12.3 MB)\n",
      "   ---------------------------------------- 0.0/12.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.4/12.3 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.5/12.3 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.1/12.3 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.4/12.3 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.8/12.3 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.3/12.3 MB 10.8 MB/s eta 0:00:00\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio-1.67.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 2.4/4.3 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.67.0-py3-none-any.whl (14 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: uritemplate, pyparsing, pyasn1, protobuf, grpcio, cachetools, rsa, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google.generativeai\n",
      "Successfully installed cachetools-5.5.0 google-ai-generativelanguage-0.6.10 google-api-core-2.21.0 google-api-python-client-2.149.0 google-auth-2.35.0 google-auth-httplib2-0.2.0 google.generativeai-0.8.3 googleapis-common-protos-1.65.0 grpcio-1.67.0 grpcio-status-1.67.0 httplib2-0.22.0 proto-plus-1.24.0 protobuf-5.28.2 pyasn1-0.6.1 pyasn1-modules-0.4.1 pyparsing-3.2.0 rsa-4.9 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3408c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aabcf57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f054272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gemini_content(transcript_text, prompt):\n",
    "    model = genai.GenerativeModel(\"gemini-pro\")\n",
    "    response=model.generate_content(prompt+transcript_text)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8adaec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-pro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "247e5f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=model.generate_content(prompt+yttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "249e8399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble learning methods, such as bagging and boosting, aim to improve model accuracy by combining multiple models.\n",
      "\n",
      "**Bagging:**\n",
      "* Creates multiple sub-datasets by sampling with replacement.\n",
      "* Trains a classifier on each sub-dataset.\n",
      "* Aggregates predictions from all models (e.g., by averaging).\n",
      "* Has low bias but high variance.\n",
      "\n",
      "**Boosting:**\n",
      "* Iteratively trains models, assigning higher weights to misclassified samples.\n",
      "* Uses weighted voting to combine predictions.\n",
      "* Has higher bias but lower variance than bagging.\n",
      "\n",
      "**Similarities:**\n",
      "* Both methods build multiple models.\n",
      "* Both use weighted voting to combine predictions.\n",
      "\n",
      "**Differences:**\n",
      "* Bagging trains models in parallel, while boosting trains them sequentially.\n",
      "* Bagging uses unweighted samples, while boosting uses weighted samples.\n",
      "* Bagging has zero bias reduction, while boosting has non-zero bias reduction.\n",
      "* Bagging is less prone to overfitting than boosting.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f41dab84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: I want this is Vimal and today you are going to talk about two of the most used methods in a simple learning begging and boosting will see how each algorithm works and what are the similarities and the difference between the two is not waste any more time and let's begin to start with let's suppose that you have a data set what begins with this question by sampling with replacement from the original data set classifier on each others to make a prediction in an assignment classifier baking courses of the other and classifications on YouTube and the differences between the two looking at how they work methods are weighted Indian sample based on the training performed in any machine learning problems in the comment section subscribe\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# convert mp3 file to wav                                                       \n",
    "# sound = AudioSegment.from_mp3(\"transcript.mp3\")\n",
    "# sound.export(\"transcript.wav\", format=\"wav\")\n",
    "\n",
    "\n",
    "# transcribe audio file                                                         \n",
    "AUDIO_FILE = \"audio.wav\"\n",
    "\n",
    "# use the audio file as the audio source                                        \n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "        audio = r.record(source)  # read the entire audio file                  \n",
    "\n",
    "        print(\"Transcription: \" + r.recognize_google(audio))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
